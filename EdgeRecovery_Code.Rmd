---
title: "Edge recovery analysis on the synthetic reference data set"
author: "Lisa M. Steinheuer"
date: "January 7, 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Idea behind work

From the gene correlation distribution analysis, it was quite obvious that for example DCA projects more correaltion into the data than in gold.
Therefore it would be good to evaluate the performance whereby the weighted networks are transformed to unweighted.
Still the question arises how the thresholds are picked.
In the initial analysis the following threshold was used: **mean+8xStd**.
Here, four different values were used namely: 4, 6, 8 and 10.
In the following script the data is generated and visualized.


# Analysis

## Set directories

```{r directories}

project <- "BeMa_Spec"

```

## Helper functions

```{r Helperfunctions, message=FALSE}

library("biclust")
library("caret")
library("mltools")
library("reshape2")
library("gridExtra")
library("WGCNA")
library("plyr")
library("dplyr")
library("magrittr")
library("rlist")
library("RColorBrewer")
library('rlist')
library('plyr')

#--------------------------------------------------------------------------------#
# Plot denisty of TOM values
cols_density <- (c('#f1eef6','#d0d1e6','#a6bddb','#74a9cf','#2b8cbe','#045a8d'))


plot_density_fun <- function(data_comp_path, data){
  load(paste0("01_BeMa_true_expression.RData"))
  plot_adj <- adjacency(trueExpr, type = "signed" , power = 9, corFnc = "bicor")
  plot_tom <-  WGCNA::TOMsimilarity(plot_adj)
  colnames(plot_tom) <- colnames(plot_tom)
  rownames(plot_tom) <- rownames(plot_tom)
  diag(plot_tom) <- NA
  density_plot <<- plot_tom %>% 
    melt() %>%
    na.omit() %>% 
    ggplot(aes(x = value))+ geom_density(color = "#8C8C85", fill = "#EEAF05")
  for (i in length(data):1){
    print(paste("Loading:", paste0(data_comp_path, data[i])))
    y <- load(paste0(data_comp_path, data[i]))
    z <- get(y)
    #print(paste("Loading:", paste0(data_comp_path, data[i]), "done!"))
    #Adjacency of predicted data set
    adj <- adjacency(z, type = "signed" , power = 9 , corFnc = "bicor")
    tom_test <- WGCNA::TOMsimilarity(adj)
    colnames(tom_test) <- colnames(adj)
    rownames(tom_test) <- rownames(adj)
    
    diag(tom_test) <- NA
    tom_test_red <- melt(tom_test)
    tom_test_red <- na.omit(tom_test_red)
    density_plot <<- density_plot + geom_density(data = tom_test_red, aes(x = value), color = "#8C8C85", fill=cols_density[i], alpha=0.8)
  }
  density_plot <<- density_plot + theme_bw(base_size = 14)+
    theme(strip.background = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
    xlab("TOM values") +
    ylab("Density")
}


#--------------------------------------------------------------------------------#
# Evaluate the performance

EvaluateSpecificity <- function(test_data, true_data, thres_value){

  #Adjacency of predicted data set
  adj <- adjacency(test_data, type = "signed" , power = 9 , corFnc = "bicor")
  tom_test <- WGCNA::TOMsimilarity(adj)
  colnames(tom_test) <- colnames(adj)
  rownames(tom_test) <- rownames(adj)
  diag(tom_test) <- NA
  tom_test_red <- melt(tom_test)
  tom_test_red <- na.omit(tom_test_red)
  threshold_test <<-  mean(tom_test_red$value) + (thres_value)*sd(tom_test_red$value)



  #threshold <<- mean(adj_test$value)+ (thres_value)*sd(adj_test$value)


  #Adjacency of filtered gold data set
  trueExpr_filtered <- true_data[rownames(test_data), colnames(test_data)]
  adj_true <- adjacency(trueExpr_filtered, type = "signed" , power = 9, corFnc = "bicor")
  tom_true <- WGCNA::TOMsimilarity(adj_true)
  colnames(tom_true) <- colnames(adj_true)
  rownames(tom_true) <- rownames(adj_true)
  tom_true_melt <- melt(tom_true)
  threshold_gold <<- mean(tom_true_melt$value) + (thres_value)*sd(tom_true_melt$value)
  print(threshold_gold)
  diag(tom_true) <- NA
  tom_true_red <- melt(tom_true)
  tom_true_red <- na.omit(tom_true_red)
  #print("Calculated both TOMs")
  
  #print("Calculated threshold")
  #binarization: above threshold of mean+8*std == 1, below == 0
  ref <<- binarize(tom_true_red, threshold = threshold_gold)
  pred <- binarize(tom_test_red, threshold = threshold_test)
  #print("Binarization done!")
  #Confusion matrix to infer Specificity and Sensitivity
  conf <<- confusionMatrix(data= as.factor(pred$value), reference= as.factor(ref$value), positive = "1",  dnn = c("Prediction", "Reference"))
  #print("Conf done!")
  mcc_val <<- round(mcc(preds = pred$value, actuals = ref$value),3)
}
#--------------------------------------------------------------------------------#
# Automatic deterination of PPV, MCC, Sen and Spec

Auto_Eval_Stepwise <- function( range, data, transpose_test_data = FALSE){
  
  Eval <- matrix(ncol = 4, nrow = length(data))
  Sum_list <<- list()
  load(paste0("01_BeMa_true_expression.RData"))
  
  for (x in 1:length(range)){
    print(paste("Started with threshold:",range[x],"xStd+mean"))
    #Real evaluation
    for (i in 1:length(data)){
      print(paste("Loading:", paste0(data[i])))
      y <- load(paste0(data[i]))
      z <- get(y)
      if (transpose_test_data == TRUE){
        EvaluateSpecificity(test_data =t(z), true_data = trueExpr, thres_value=range[x])
      } else {
      EvaluateSpecificity(test_data = z, true_data = trueExpr, thres_value=range[x])}
      print("The confusion matrix:")
      print(conf$table)
      Eval[i,1] <- round(conf$byClass['Recall'], 2)
      Eval[i,2] <- mcc_val
      Eval[i,3] <- round(conf$byClass["Sensitivity"], 2)
      Eval[i,4] <- round(conf$byClass["Precision"], 2)

    }
    rownames(Eval) <- c(paste0("Drop_", 1:6))
    colnames(Eval) <- c("Recall", "MCC", "Sensitivity", "Precision")
    Sum_list[[x]] <<- Eval
    
  }
  names(Sum_list) <<- paste0(range, "xStd+mean")
  
  return(Sum_list)
}

range <- c(1,2)
```

## Data generation

### Sparse

```{r sparse_data , eval=FALSE}
data <- list.files(pattern = "01_BeMa_dropExpr*")

Auto_Eval_Stepwise(range, data= data)
save(Sum_list, file= paste0("01_", project, "_EvalDrop.RData"))


plot_density_fun(data = data, data_comp_path  = rdata_input)

svg(paste0(results, "000_DensityPlot_Sparse.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  coord_cartesian(xlim = c(0,0.01)) +
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()



```

### DrImpute

```{r drimpute_data , eval=FALSE}
data <- list.files(pattern = "*_DrImpute.RData")

Auto_Eval_Stepwise_t(range, data= data, transpose_test_data = TRUE)
save(Sum_list, file= paste0("01_", project, "_EvalDrImpute.RData"))


plot_density_fun(data = data, data_comp_path  = rdata_input)

svg(paste0(results, "000_DensityPlot_SAVER.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()
```


### SAVER

```{r saver_data , eval=FALSE}
data <- list.files(pattern = "*_SAVER.RData")

Auto_Eval_Stepwise(range, data= data)
save(Sum_list, file= paste0("01_", project, "_EvalSAVER.RData"))


plot_density_fun(data = data, data_comp_path  = rdata_input)

svg(paste0(results, "000_DensityPlot_SAVER.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()
```


### DCA

```{r dca_data , eval=FALSE}
data <- list.files(pattern = "*_DCA.RData")

Auto_Eval_Stepwise(range, data= data)
save(Sum_list, file= paste0("01_", project, "_EvalDCA.RData"))


plot_density_fun(data = data, data_comp_path  = rdata_input)

svg(paste0(results, "000_DensityPlot_DCA.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()

```

### scNPF

```{r dca_data , eval=FALSE}
data <- list.files(path = rdata_input,
                   pattern = "*_scNPF.RData")

Auto_Eval_Stepwise(range, data= data, transpose_test_data =TRUE)
save(Sum_list, file= paste0("01_", project, "_EvalscNPF.RData"))

plot_density_fun(data = data, data_comp_path  = rdata_input)
density_plot <- density_plot + coord_cartesian(ylim = c(0,250))
svg(paste0(results, "000_DensityPlot_scNPF.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()
```

### scNPF Gold NTWK

```{r dca_data , eval=FALSE}
data <- list.files(pattern = "*_scNPF_GoldNTWK.RData")

Auto_Eval_Stepwise(range, data= data, transpose_test_data = TRUE)
save(Sum_list, file= paste0("01_", project, "_EvalscNPF_GoldNTWK.RData"))


plot_density_fun(data = data, data_comp_path  = rdata_input)

svg(paste0(results, "000_DensityPlot_scNPF_Gold.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()

```

### ENHANCE

```{r dca_data , eval=FALSE}
data <- list.files(pattern = "*_ENHANCE.RData")

Auto_Eval_Stepwise(range, data= data)
save(Sum_list, file= paste0("01_", project, "_EvalENHANCE.RData"))

plot_density_fun(data = data, data_comp_path  = rdata_input)

svg(paste0(results, "000_DensityPlot_ENHANCE.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()
```

### DISC

```{r dca_data , eval=FALSE}
data <- list.files(pattern = "*_DISC.RData")

Auto_Eval_Stepwise(range,  data= data)
save(Sum_list, file= paste0("01_", project, "_EvalDISC.RData"))

plot_density_fun(data = data, data_comp_path  = rdata_input)

svg(paste0(results, "000_DensityPlot_DISC.svg"), height = 5, width = 8)
density_plot <- density_plot + 
  coord_cartesian(xlim = c(0,0.1)) +
  theme_bw(base_size = 20) %+replace%
  theme(
    panel.grid = element_blank(),
    complete = TRUE) +
    theme(axis.text=element_text(size=20))
print(density_plot)
dev.off()

```

## Combining the data into a single representation

In this section, we would like to compare all the different results across imputation, sparsity and threshold choice.
Previous analysis already showed that, we need different evaluation measures.
Therefore many different data representations are indicated in the following.

### Gathering the data
```{r plotting_data_gathering}
# Combining the inidividual matrices
# Which data?
data <- list.files( pattern = "01_BeMa_Spec_Eval*")
name <- gsub(data, pattern="01_BeMa_Spec_Eval|.RData", replacement="")


#-----------------------------------------------------------------------------------------------------------#
# Gather data together into one  list element
Final <- list()
for(x in 1:length(data)){
  load(paste0(data[x]))
  df<- melt(Sum_list)
  # add information about imputation method since all entries are called after sparisty level
  df$Imputation <- rep(name[x], dim(df)[1])
  Final[[x]] <- df
  }
#-----------------------------------------------------------------------------------------------------------#
# Built ultimate dataframe where all the information is contained 
df <- list.rbind(Final)

# Reorganize lists in such that each data sparisty level
colnames(df) <- c("Source_Sparsity", "EvalMetric", "value", "Threshold", "Imputation")
# Rename and reordering the factor levels of imputation column
df$Imputation <- revalue(df$Imputation, c("Drop"="Sparse"))
df$Imputation <- factor(df$Imputation, levels = c("Sparse", "DrImpute", "SAVER", "DCA", "scNPF", "scNPF_GoldNTWK", "ENHANCE", "DISC"))
df$EvalMetric <- factor(df$EvalMetric, levels = c("Precision", "Recall", "MCC", "Sensitivity"))

# Renaming the sparsity levels eg. from Drop_1 to 75% Sparsity
df$Source_Sparsity <- revalue(df$Source_Sparsity, c("Drop_1"="84%",
                                    "Drop_2"="75%",
                                    "Drop_3"="66%",
                                    "Drop_4"="55%",
                                    "Drop_5"="46%",
                                    "Drop_6"="40%"))
# Reordering these factor levels
df$Source_Sparsity <- factor(df$Source_Sparsity, levels = c("40%", "46%", "55%", "66%", "75%", "84%"))

# Reordering the factor levels of thresholds
# df$Threshold <- factor(df$Threshold, levels = c("1xStd+mean", "2xStd+mean", "3xStd+mean","4xStd+mean"))
#df$Threshold <- factor(df$Threshold, levels = c("2xStd+mean", "3xStd+mean"))

save(df, file= paste0("04_", project, "_CombinedDF.RData"))

```

### Plot

Lastly, we focus on one single evaluation such as the MCC to break up the information gained from the individual threshold parameters.



```{r plot_results4, fig.width = 8, fig.height=10 }
library("RColorBrewer")
p <- df %>% 
  filter(EvalMetric =="Precision") %>% 
  ggplot(aes(x =Source_Sparsity, y=value, colour=Imputation, group=Imputation))+
  geom_line(size =1.6, color = "black") +
  geom_line(size =1.5) +
  geom_point(size= 2,aes(x=Source_Sparsity, y=value, color=Imputation)) +
  theme_bw(base_size = 14)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(strip.background = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  scale_color_manual(values=c("#C32813",brewer.pal(9, "Greys")[-c(1)])) +
  facet_grid(cols = vars(Threshold)) +
  # labs(title = "Precision on downsampled bulk",
  #               subtitle = "Model performace of each imputation method across each sparsity level") +
  xlab("Dropout") +
  ylab("Precision")

svg(paste0("R_01_", project, "_PrecisionOverImpSparse_facets.svg"),
    width=10, 
    height=5)
print(p)
dev.off()


p <- df %>% 
  filter(EvalMetric =="Recall") %>% 
  ggplot(aes(x =Source_Sparsity, y=value, colour=Imputation, group=Imputation))+
  geom_line(size =1.6, color = "black") +
  geom_line(size =1.5) +
  geom_point(size= 2,aes(x=Source_Sparsity, y=value, color=Imputation)) +
  theme_bw(base_size = 14)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(strip.background = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  scale_color_manual(values=c("#C32813",brewer.pal(9, "Greys")[-c(1)])) +
  facet_grid(cols = vars(Threshold)) +
  # labs(title = "Recall on downsampled bulk",
  #               subtitle = "Model performace of each imputation method across each sparsity level") +
  xlab("Dropout") +
  ylab("Recall")

svg(paste0("R_01_", project, "_RecallOverImpSparse_facets.svg"),
    width=10, 
    height=5)
print(p)
dev.off()

```

```{r}
p <- df %>% 
  filter(EvalMetric =="Precision" | EvalMetric =="MCC" | EvalMetric == "Recall") %>%  filter(Threshold == "1xStd+mean") %>% 
  ggplot(aes(x =Source_Sparsity, y=value, colour=Imputation, group=Imputation))+
  geom_line(size =2.1, color = "black") +
  geom_line(size =2) +
  geom_point(size= 3,aes(x=Source_Sparsity, y=value, color=Imputation)) +
  theme_bw(base_size = 22)+
  theme(axis.text=element_text(size=20))+
  theme(axis.text.x = element_text(angle = 0))+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  theme(legend.position="bottom") +
  scale_color_manual(values=c('black','#D45587','#FBAB6D', '#7570b3', '#33a02c','#b2df8a','#1f78b4','#a6cee3')) +
  facet_grid(cols = vars(EvalMetric)) +
  labs(title = "Edge recovery",
                subtitle = "Model performace of each imputation method across each sparsity level")+
  xlab("Dropout") +
  ylab("Value")

svg(paste0("R_01_", project, "_EvalOverImpSparse_TH2_recall.svg"),
    width=14.1, 
    height=8)
print(p)
dev.off()


p  
```

Lastly, we focus on one single evaluation such as the MCC to break up the information gained from the individual threshold parameters.



```{r plot_results4, fig.width = 8, fig.height=10 }

p <- df %>% 
  filter(EvalMetric =="MCC") %>% 
  ggplot(aes(x =Source_Sparsity, y=value, colour=Imputation, group=Imputation))+
  geom_line(size =1.6, color = "black") +
  geom_line(size =1.5)+
  geom_point(size =2,aes( x=Source_Sparsity, y=value, color=Imputation)) +
  theme_bw(base_size = 14)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(strip.background = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  scale_color_manual(values=c("#C32813",brewer.pal(9, "Greys")[-c(1)])) +
  facet_grid(cols = vars(Threshold)) 
  
  # p <- p + labs(title = "MCC on downsampled bulk",
  #               subtitle = "Model performace of each imputation method across each sparsity level")
p <- p + xlab("Dropout") +
  ylab("MCC")
svg(paste0("R_01_", project, "_MCCoverImpSparse_facets.svg"),
    width=10, 
    height=5)
print(p)
dev.off()




```



# Session Info
```{r}
sessionInfo()
```

